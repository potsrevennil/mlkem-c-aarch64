#!/usr/bin/env python
# SPDX-License-Identifier: Apache-2.0

import platform
import sys
import os
import subprocess
import logging
import click
import hashlib
from functools import reduce
from enum import IntEnum
from typing import Optional


def config_logger(verbose):
    if verbose:
        logging.basicConfig(
            stream=sys.stdout,
            format="%(levelname)-5s > %(message)s",
            level=logging.DEBUG,
        )
    else:
        logging.basicConfig(
            stream=sys.stdout,
            format="%(levelname)-5s > %(message)s",
            level=logging.INFO,
        )


def sha256sum(result):
    m = hashlib.sha256()
    m.update(result)
    return m.hexdigest()


class TEST_TYPES(IntEnum):
    MLKEM = 1
    BENCH = 2
    NISTKAT = 3
    KAT = 4
    BENCH_COMPONENTS = 5

    def __str__(self):
        return self.name.lower()

    def desc(self):
        match self:
            case TEST_TYPES.MLKEM:
                return "Functional Test"
            case TEST_TYPES.BENCH:
                return "Benchmark"
            case TEST_TYPES.BENCH_COMPONENTS:
                return "Benchmark Components"
            case TEST_TYPES.NISTKAT:
                return "Nistkat Test"
            case TEST_TYPES.KAT:
                return "Kat Test"

    def bin(self):
        match self:
            case TEST_TYPES.MLKEM:
                return "test_kyber"
            case TEST_TYPES.BENCH:
                return "bench_kyber"
            case TEST_TYPES.BENCH_COMPONENTS:
                return "bench_components_kyber"
            case TEST_TYPES.NISTKAT:
                return "gen_NISTKAT"
            case TEST_TYPES.KAT:
                return "gen_KAT"

    def bin_path(self, scheme, opt):
        return f'test/build/{scheme.name.lower()}/bin/{self.bin()}{scheme.suffix()}_{"opt" if opt else "ref" }'


class SCHEME(IntEnum):
    MLKEM512 = 1
    MLKEM768 = 2
    MLKEM1024 = 3

    def __str__(self):
        match self:
            case SCHEME.MLKEM512:
                return "ML-KEM-512"
            case SCHEME.MLKEM768:
                return "ML-KEM-768"
            case SCHEME.MLKEM1024:
                return "ML-KEM-1024"

    def __iter__(self):
        return self

    def __next__(self):
        return self + 1

    def suffix(self):
        return self.name.removeprefix("MLKEM")


def parse_meta(scheme, field):
    result = subprocess.run(
        [
            "yq",
            "-r",
            "--arg",
            "scheme",
            str(scheme),
            f'.implementations.[] | select(.name == $scheme) | ."{field}"',
            "./META.yml",
        ],
        capture_output=True,
        encoding="utf-8",
        universal_newlines=False,
    )
    return result.stdout.strip()


def github_summary(title: str, test: TEST_TYPES, results):
    summary_file = os.environ.get("GITHUB_STEP_SUMMARY")

    res = list(results.values())

    if isinstance(results[SCHEME.MLKEM512], str):
        summaries = list(
            map(
                lambda s: f" {s} |",
                reduce(
                    lambda acc, s: [
                        line1 + " | " + line2 for line1, line2 in zip(acc, s)
                    ],
                    [s.splitlines() for s in res],
                ),
            )
        )
        summaries = [f"| {test.desc()} |" + summaries[0]] + [
            "| |" + x for x in summaries[1:]
        ]
    else:
        summaries = [
            reduce(
                lambda acc, b: f"{acc} " + (":x: |" if b else ":white_check_mark: |"),
                res,
                f"| {test.desc()} |",
            )
        ]

    def find_last_consecutive_match(l, s):
        for i, v in enumerate(l[s + 1 :]):
            if not v.startswith("|") or not v.endswith("|"):
                return i + 1
        return len(l)

    def add_summaries(fn, title, summaries):
        summary_title = "| Tests |"
        summary_table_format = "| ----- |"
        for s in SCHEME:
            summary_title += f" {s} |"
            summary_table_format += " ----- |"

        with open(fn, "r") as f:
            pre_summaries = [x for x in f.read().splitlines() if x]
            if title in pre_summaries:
                if summary_title not in pre_summaries:
                    summaries = [summary_title, summary_table_format] + summaries
                    pre_summaries = (
                        pre_summaries[: pre_summaries.index(title) + 1]
                        + summaries
                        + pre_summaries[pre_summaries.index(title) + 1 :]
                    )
                else:
                    i = find_last_consecutive_match(
                        pre_summaries, pre_summaries.index(title)
                    )
                    pre_summaries = pre_summaries[:i] + summaries + pre_summaries[i:]
                return ("w", pre_summaries)
            else:
                pre_summaries = [
                    title,
                    summary_title,
                    summary_table_format,
                ] + summaries
                return ("a", pre_summaries)

    if summary_file is not None:
        (access_mode, summaries) = add_summaries(summary_file, title, summaries)
        with open(summary_file, access_mode) as f:
            print("\n".join(summaries), file=f)


class State(object):

    def __init__(self):
        self.verbose = False
        self.cross_prefix = ""
        self.cflags = ""
        self.arch_flags = ""
        self.auto = True
        self.compile = True
        self.run = True

    def compile_schemes(
        self,
        test_type,
        extra_make_envs={},
        extra_make_args=[],
    ):
        """compile or cross compile with some extra environment variables and makefile arguments"""

        def dict2str(dict):
            s = ""
            for k, v in dict.items():
                s += f"{k}={v} "
            return s

        args = [
            "make",
            f"CROSS_PREFIX={self.cross_prefix}",
            f"{test_type}",
        ] + extra_make_args

        logging.info(dict2str(extra_make_envs) + " ".join(args))

        p = subprocess.run(
            args,
            stdout=subprocess.DEVNULL if not self.verbose else None,
            env=os.environ.copy() | extra_make_envs,
        )

        if p.returncode != 0:
            logging.error(f"make failed: {p.returncode}")
            sys.exit(1)

    def run_scheme(
        self,
        bin,
        run_as_root=False,
        exec_wrapper=None,
    ):
        """Run the binary in all different ways"""
        cmd = [f"./{bin}"]
        if self.cross_prefix and platform.system() != "Darwin":
            logging.info(f"Emulating {bin} with QEMU")
            if "x86_64" in self.cross_prefix:
                cmd = ["qemu-x86_64"] + cmd
            elif "aarch64" in self.cross_prefix:
                cmd = ["qemu-aarch64"] + cmd
            else:
                logging.info(
                    f"Emulation for {self.cross_prefix} on {platform.system()} not supported"
                )

        if run_as_root:
            logging.info(
                f"Running {bin} as root -- you may need to enter your root password."
            )
            cmd = ["sudo"] + cmd

        if exec_wrapper:
            logging.info(f"Running {bin} with customized wrapper.")
            exec_wrapper = exec_wrapper.split(" ")
            cmd = exec_wrapper + cmd

        logging.info(" ".join(cmd))
        result = subprocess.run(
            cmd,
            capture_output=True,
            universal_newlines=False,
        )

        if result.returncode != 0:
            logging.error(
                f"Running '{cmd}' failed: {result.returncode} {result.stderr.decode()}"
            )
            sys.exit(1)

        return result.stdout

    def run_schemes(
        self,
        test_type,
        opt,
        run_as_root=False,
        exec_wrapper=None,
        actual_proc=None,
        expect_proc=None,
    ):
        fail = False
        results = {}
        for scheme in SCHEME:
            result = self.run_scheme(
                test_type.bin_path(scheme, opt),
                run_as_root,
                exec_wrapper,
            )

            if actual_proc is not None and expect_proc is not None:
                actual = actual_proc(result)
                expect = expect_proc(scheme)
                f = actual != expect
                fail = fail or f
                if f:
                    logging.error(
                        f"{scheme} failed, expecting {expect}, but getting {actual}"
                    )
                else:
                    logging.info(f"{scheme} passed")
                results[scheme] = f
            else:
                logging.info(f"{scheme}")
                logging.info(f"\n{result}")
                results[scheme] = result.decode()

        if fail:
            sys.exit(1)

        return results

    def test(
        self,
        test_type: TEST_TYPES,
        opt,
        extra_make_envs={},
        extra_make_args=[],
        actual_proc=None,
        expect_proc=None,
        run_as_root=False,
        exec_wrapper=None,
    ):
        config_logger(self.verbose)

        logging.info(
            f'{test_type.desc()} ({"cross" if self.cross_prefix else "native"}, {"opt" if opt else "non-opt"})'
        )

        make_envs = (
            {"CFLAGS": f"{self.cflags}"} if self.cflags is not None else {}
        ) | (
            {"ARCH_FLAGS": f"{self.arch_flags}"} if self.arch_flags is not None else {}
        )
        make_envs.update(extra_make_envs)

        if self.compile:
            self.compile_schemes(
                test_type,
                make_envs,
                extra_make_args
                + list(
                    set([f"OPT={int(opt)}", f"AUTO={int(self.auto)}"])
                    - set(extra_make_args)
                ),
            )

        results = None
        if self.run:
            results = self.run_schemes(
                test_type,
                opt,
                run_as_root,
                exec_wrapper,
                actual_proc,
                expect_proc,
            )

            title = (
                "## "
                + ("Cross" if self.cross_prefix else "Native")
                + " "
                + ("Opt" if opt else "Non-opt")
                + " Tests"
            )
            github_summary(title, test_type, results)

        return results


def __callback(n):
    def callback(ctx, param, value):
        state = ctx.ensure_object(State)
        state.__dict__[n] = value
        return value

    return callback


_shared_options = [
    click.option(
        "-v",
        "--verbose",
        expose_value=False,
        is_flag=True,
        show_default=True,
        default=False,
        type=bool,
        help="Show verbose output or not",
        callback=__callback("verbose"),
    ),
    click.option(
        "-cp",
        "--cross-prefix",
        expose_value=False,
        default="",
        show_default=True,
        nargs=1,
        help="Cross prefix for compilation",
        callback=__callback("cross_prefix"),
    ),
    click.option(
        "--cflags",
        expose_value=False,
        nargs=1,
        help="Extra cflags to passed in (e.g. '-mcpu=cortex-a72')",
        callback=__callback("cflags"),
    ),
    click.option(
        "--arch-flags",
        expose_value=False,
        nargs=1,
        help="Extra arch flags to passed in (e.g. '-march=armv8')",
        callback=__callback("arch_flags"),
    ),
    click.option(
        "--auto/--no-auto",
        expose_value=False,
        is_flag=True,
        show_default=True,
        default=True,
        help="Allow makefile to auto configure system specific preprocessor",
        callback=__callback("auto"),
    ),
    click.option(
        "--compile/--no-compile",
        expose_value=False,
        is_flag=True,
        show_default=True,
        default=True,
        help="Determine to compile the binary or not",
        callback=__callback("compile"),
    ),
    click.option(
        "--run/--no-run",
        expose_value=False,
        is_flag=True,
        show_default=True,
        default=True,
        help="Determine to run the compiled binary or not",
        callback=__callback("run"),
    ),
]

_opt_option = click.option(
    "--opt/--no-opt",
    is_flag=True,
    show_default=True,
    default=True,
    help="Choose whether to enable assembly optimizations (if present)",
)

_bench_options = [
    click.option(
        "-c",
        "--cycles",
        nargs=1,
        type=click.Choice(["NO", "PMU", "PERF", "M1"]),
        show_default=True,
        default="NO",
        help="Method for counting clock cycles. PMU requires (user-space) access to the Arm Performance Monitor Unit (PMU). PERF requires a kernel with perf support. M1 only works on Apple silicon.",
    ),
    click.option(
        "-o",
        "--output",
        nargs=1,
        help="Path to output file in json format",
    ),
    click.option(
        "-r",
        "--run-as-root",
        is_flag=True,
        show_default=True,
        default=False,
        type=bool,
        help="Benchmarking binary is run with sudo.",
    ),
    click.option(
        "-w",
        "--exec-wrapper",
        help="Run the benchmark binary with the user-customized wrapper.",
    ),
    click.option(
        "-t",
        "--mac-taskpolicy",
        nargs=1,
        type=click.Choice(["utility", "background", "maintenance"]),
        hidden=platform.system() != "Darwin",
        show_default=True,
        default=None,
        help="Run the program using the specified QoS clamp. Applies to MacOS only. Setting this flag to 'background' guarantees running on E-cores. This is an abbreviation of --exec-wrapper 'taskpolicy -c {mac_taskpolicy}'.",
    ),
    click.option(
        "--components",
        is_flag=True,
        type=bool,
        show_default=True,
        default=False,
        help="Benchmark low-level components",
    ),
]


def add_options(options):
    return lambda func: reduce(lambda f, o: o(f), reversed(options), func)


@click.group(invoke_without_command=True)
def cli():
    pass


@cli.command(
    short_help="Run the functional tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@click.make_pass_decorator(State, ensure=True)
@_opt_option
def func(state: State, opt):
    def expect(scheme):
        sk_bytes = parse_meta(scheme, "length-secret-key")
        pk_bytes = parse_meta(scheme, "length-public-key")
        ct_bytes = parse_meta(scheme, "length-ciphertext")

        return (
            f"CRYPTO_SECRETKEYBYTES:  {sk_bytes}\n"
            + f"CRYPTO_PUBLICKEYBYTES:  {pk_bytes}\n"
            + f"CRYPTO_CIPHERTEXTBYTES: {ct_bytes}\n"
        )

    state.test(
        TEST_TYPES.MLKEM,
        opt,
        actual_proc=lambda result: str(result, encoding="utf-8"),
        expect_proc=expect,
    )


@cli.command(
    short_help="Run the nistkat tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@_opt_option
@click.make_pass_decorator(State, ensure=True)
def nistkat(state: State, opt):
    state.test(
        TEST_TYPES.NISTKAT,
        opt,
        actual_proc=sha256sum,
        expect_proc=lambda scheme: parse_meta(scheme, "nistkat-sha256"),
    )


@cli.command(
    short_help="Run the kat tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@_opt_option
@click.make_pass_decorator(State, ensure=True)
def kat(state: State, opt):
    state.test(
        TEST_TYPES.KAT,
        opt,
        actual_proc=sha256sum,
        expect_proc=lambda scheme: parse_meta(scheme, "kat-sha256"),
    )


@cli.command(
    short_help="Run the benchmarks for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@_opt_option
@add_options(_bench_options)
@click.make_pass_decorator(State, ensure=True)
def bench(
    state: State,
    opt,
    cycles,
    output,
    run_as_root,
    exec_wrapper,
    mac_taskpolicy,
    components,
):
    config_logger(state.verbose)

    if components is False:
        bench_type = TEST_TYPES.BENCH
    else:
        bench_type = TEST_TYPES.BENCH_COMPONENTS
        output = False

    if mac_taskpolicy:
        if exec_wrapper:
            logging.error(f"cannot set both --mac-taskpolicy and --exec-wrapper")
            sys.exit(1)
        else:
            exec_wrapper = f"taskpolicy -c {mac_taskpolicy}"

    results = state.test(
        bench_type,
        opt,
        extra_make_args=[f"CYCLES={cycles}"],
        run_as_root=run_as_root,
        exec_wrapper=exec_wrapper,
    )

    if results is not None and output is not None and components is False:
        import json

        with open(output, "w") as f:
            v = []
            for scheme in results:
                schemeStr = str(scheme)
                r = results[scheme]

                # The first 3 lines of the output are expected to be
                # keypair cycles=X
                # encaps cycles=X
                # decaps cycles=X

                lines = [
                    line.decode() for line in r.splitlines() if "=" in line.decode()
                ]

                d = {k: int(v) for k, v in (l.split("=") for l in lines)}
                for primitive in ["keypair", "encaps", "decaps"]:
                    v.append(
                        {
                            "name": f"{schemeStr} {primitive}",
                            "unit": "cycles",
                            "value": d[f"{primitive} cycles"],
                        }
                    )
            f.write(json.dumps(v))


@cli.command(
    short_help="Run all tests (except benchmark for now)",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@add_options(
    [
        click.option(
            "--opt",
            nargs=1,
            type=click.Choice(["ALL", "OPT", "NO_OPT"], case_sensitive=False),
            show_default=True,
            default="ALL",
            help="Determine whether to compile/run the opt/no_opt binary or both",
        ),
        click.option(
            "--func/--no-func",
            is_flag=True,
            show_default=True,
            default=True,
            help="Determine whether to run func test or not",
        ),
        click.option(
            "--kat/--no-kat",
            is_flag=True,
            show_default=True,
            default=True,
            help="Determine whether to run kat test or not",
        ),
        click.option(
            "--nistkat/--no-nistkat",
            is_flag=True,
            show_default=True,
            default=True,
            help="Determine whether to run nistkat test or not",
        ),
    ]
)
@click.make_pass_decorator(State, ensure=True)
def all(
    state: State,
    opt,
    func,
    kat,
    nistkat,
):
    auto_flag = "auto" if state.auto else "no-auto"
    compile_mode = "cross" if state.cross_prefix else "native"

    def _cmd(cmd, opt_flag, compile_flag, run_flag):
        return [
            "tests",
            f"{cmd}",
            f"--cross-prefix={state.cross_prefix}",
            *([f"--cflags={state.cflags}"] if state.cflags is not None else []),
            f"--{opt_flag}",
            f"--{auto_flag}",
            f"--{compile_flag}",
            f"--{run_flag}",
            *(["--verbose"] if state.verbose else []),
        ]

    def __cmds(opt_flag, compile_flag, run_flag):
        return (
            ([_cmd("func", opt_flag, compile_flag, run_flag)] if func else [])
            + ([_cmd("kat", opt_flag, compile_flag, run_flag)] if kat else [])
            + ([_cmd("nistkat", opt_flag, compile_flag, run_flag)] if nistkat else [])
        )

    def _cmds(compile_flag, run_flag):
        return (
            __cmds("opt", compile_flag, run_flag)
            if (opt == "ALL" or opt == "OPT")
            else []
        ) + (
            __cmds("no-opt", compile_flag, run_flag)
            if (opt == "ALL" or opt == "NO_OPT")
            else []
        )

    compile_cmds = [] if not state.compile else _cmds("compile", "no-run")
    run_cmds = [] if not state.run else _cmds("no-compile", "run")

    exit_code = 0

    gh_env = os.environ.get("GITHUB_ENV")

    # sequentially compile
    for c in compile_cmds:
        if gh_env is not None:
            print(
                f'::group::compile {compile_mode} {c[4].removeprefix("--")} {c[1]} test'
            )
        result = subprocess.run(
            c,
            encoding="utf-8",
            capture_output=True,
            universal_newlines=False,
        )
        exit_code = exit_code or result.returncode
        print(result.stdout)
        if result.returncode != 0:
            print(f"{result.stderr}")
        if gh_env is not None:
            print(f"::endgroup::")

    # parallelly run
    procs = [
        subprocess.Popen(
            p, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding="utf-8"
        )
        for p in run_cmds
    ]

    for p in procs:
        out, err = p.communicate()
        exit_code = exit_code or p.returncode

        if gh_env is not None:
            print(
                f'::group::run {compile_mode} {p.args[4].removeprefix("--")} {p.args[1]} test'
            )
        print(out)
        if p.returncode != 0:
            print(err)
        if gh_env is not None:
            print(f"::endgroup::")

    exit(exit_code)


if __name__ == "__main__":
    cli()
